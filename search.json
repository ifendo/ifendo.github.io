[
  {
    "objectID": "tools.html",
    "href": "tools.html",
    "title": "Tools",
    "section": "",
    "text": "R Related\n\n\nPython Related\n\n\nAI Related"
  },
  {
    "objectID": "blog/30Aug2025-prompt-engineering-tips/index.html",
    "href": "blog/30Aug2025-prompt-engineering-tips/index.html",
    "title": "Prompt Engineering",
    "section": "",
    "text": "Prompt engineering has become an essential skill for developers working with AI models. Whether you’re using ChatGPT, Claude, or other language models, the quality of your prompts directly impacts the usefulness of the responses you get."
  },
  {
    "objectID": "blog/30Aug2025-prompt-engineering-tips/index.html#core-principles",
    "href": "blog/30Aug2025-prompt-engineering-tips/index.html#core-principles",
    "title": "Prompt Engineering",
    "section": "Core Principles",
    "text": "Core Principles\nThe foundation of good prompt engineering rests on these key principles:\n\nUse role-playing - “Act as a senior data engineer mentoring a junior. Explain why data quality matters in ETL processes”\nBe specific and clear - Instead of “Write about AI”, try “Write a 300-word explanation of transformers for developers”\nProvide context and examples - Include role, audience, and format requirements\nUse structured formats - JSON, bullet points, step-by-step instructions\nIterate and refine - Start simple, add complexity gradually"
  },
  {
    "objectID": "blog/30Aug2025-prompt-engineering-tips/index.html#role-context-setting",
    "href": "blog/30Aug2025-prompt-engineering-tips/index.html#role-context-setting",
    "title": "Prompt Engineering",
    "section": "Role & Context Setting",
    "text": "Role & Context Setting\nSetting the right context dramatically improves response quality. Here’s how to do it effectively:\nSet the scene:\nYou are a senior Python developer reviewing FastAPI code.\nFocus on performance and security issues.\nYour audience is junior developers.\nProvide examples (Few-shot prompting):\nClassify sentiment:\n\"I love this!\" → Positive\n\"This is terrible\" → Negative\n\"It's okay\" → Neutral\n\nNow classify: \"Amazing quality!\"\nThis approach gives the AI model concrete examples of what you expect, leading to more consistent results."
  },
  {
    "objectID": "blog/30Aug2025-prompt-engineering-tips/index.html#advanced-techniques",
    "href": "blog/30Aug2025-prompt-engineering-tips/index.html#advanced-techniques",
    "title": "Prompt Engineering",
    "section": "Advanced Techniques",
    "text": "Advanced Techniques\n\nChain of Thought\nBreak down complex problems into steps:\nCalculate 15% tip on $47.50\n\nThink step by step:\n1. Convert percentage to decimal: 15% = 0.15\n2. Multiply: $47.50 × 0.15 = $7.125\n3. Round to nearest cent: $7.13\n\n\nOutput Formatting\nSpecify exactly how you want the response structured:\nRespond in JSON:\n{\"summary\": \"...\", \"confidence\": 0.85}\n\n\nConstraints\nSet clear boundaries:\n\nLength: “In exactly 100 words”\nStyle: “Use bullet points only”\n\nScope: “Python solutions only”"
  },
  {
    "objectID": "blog/30Aug2025-prompt-engineering-tips/index.html#common-pitfalls-best-practices",
    "href": "blog/30Aug2025-prompt-engineering-tips/index.html#common-pitfalls-best-practices",
    "title": "Prompt Engineering",
    "section": "Common Pitfalls & Best Practices",
    "text": "Common Pitfalls & Best Practices\n\n\n\n\n\n\nAvoid These Mistakes\n\n\n\n\nVague instructions that leave too much room for interpretation\nMissing context about your specific use case\nOverloading a single prompt with too many requirements\n\n\n\n\n\n\n\n\n\nBest Practices\n\n\n\n\nTest your prompts with edge cases\nDocument successful prompt patterns for reuse\nVersion control your prompts like code\nUse system prompts for consistency across conversations\nControl temperature settings (creativity vs precision)"
  },
  {
    "objectID": "blog/30Aug2025-prompt-engineering-tips/index.html#practical-examples",
    "href": "blog/30Aug2025-prompt-engineering-tips/index.html#practical-examples",
    "title": "Prompt Engineering",
    "section": "Practical Examples",
    "text": "Practical Examples\n\nCode Generation Prompt\nHere’s a comprehensive prompt template for generating production-ready code:\n&lt;role&gt;\nYou are a senior Python expert developer with expertise in clean, \nproduction-ready code. Your audience is experienced developers who \nvalue efficiency and maintainability.\n&lt;/role&gt;\n\n&lt;task&gt;\nGenerate Python code following these exact specifications:\n&lt;/task&gt;\n\n&lt;code_requirements&gt;\n- Python 3.10+ syntax with complete type annotations\n- PEP8 compliant (must pass `ruff check .`)\n- Prefer standard library; avoid unnecessary dependencies\n- Use only stable, popular packages when needed\n- Use `polars` instead of `pandas` for data operations\n- Include docstrings with examples\n- Minimal implementation - no over-engineering\n&lt;/code_requirements&gt;\n\n&lt;output_format&gt;\nComplete, runnable code with:\n1. Necessary imports at top\n2. Type-annotated functions with docstrings\n3. Main execution (if applicable)\n4. Small usage example\n5. Pytest unit test (if relevant)\n&lt;/output_format&gt;\n\n\nCode Review Prompt\nFor reviewing existing code:\n&lt;role&gt;\nYou are a senior Python code reviewer with expertise in \nproduction-ready code quality.\n&lt;/role&gt;\n\n&lt;review_requirements&gt;\n- Check Python 3.10+ syntax and type annotations\n- Verify PEP8 compliance\n- Evaluate package choices\n- Identify over-engineering or unnecessary complexity\n- Review comment quality\n&lt;/review_requirements&gt;\n\n&lt;output_format&gt;\n## Issues Found\n- **Critical**: [Security, functionality issues]\n- **Improvements**: [Code quality suggestions]\n- **Style**: [PEP8, formatting issues]\n\n## Recommendations\n[Specific, actionable suggestions with examples]\n&lt;/output_format&gt;"
  },
  {
    "objectID": "blog/30Aug2025-prompt-engineering-tips/index.html#key-takeaways",
    "href": "blog/30Aug2025-prompt-engineering-tips/index.html#key-takeaways",
    "title": "Prompt Engineering",
    "section": "Key Takeaways",
    "text": "Key Takeaways\nEffective prompt engineering is about clear communication with AI models. The time you invest in crafting good prompts pays dividends in the quality and usefulness of the responses you receive.\nStart with these fundamentals: 1. Be specific about what you want 2. Provide context and examples 3. Structure your requests clearly 4. Iterate and improve your prompts over time\nAs AI models continue to evolve, these prompt engineering skills will become increasingly valuable for developers who want to leverage AI effectively in their workflows."
  },
  {
    "objectID": "blog/30Aug2025-prompt-engineering-tips/index.html#references",
    "href": "blog/30Aug2025-prompt-engineering-tips/index.html#references",
    "title": "Prompt Engineering",
    "section": "References",
    "text": "References\n\nOpenAI Prompting Guide\nAnthropic Prompt Engineering\nPrompt Engineering Guide"
  },
  {
    "objectID": "blog/07Sep2025-fastmcp-http-transport/index.html",
    "href": "blog/07Sep2025-fastmcp-http-transport/index.html",
    "title": "FastMCP HTTP Transport: Calling MCP Servers Over HTTP",
    "section": "",
    "text": "FastMCP provides an HTTP transport layer for Model Context Protocol (MCP) servers, but requires a proper MCP client to communicate. This post demonstrates the correct way to call an MCP server over HTTP using FastMCP."
  },
  {
    "objectID": "blog/07Sep2025-fastmcp-http-transport/index.html#what-is-fastmcp-http-transport",
    "href": "blog/07Sep2025-fastmcp-http-transport/index.html#what-is-fastmcp-http-transport",
    "title": "FastMCP HTTP Transport: Calling MCP Servers Over HTTP",
    "section": "What is FastMCP HTTP Transport?",
    "text": "What is FastMCP HTTP Transport?\nFastMCP’s HTTP transport exposes MCP servers over HTTP, but maintains the MCP protocol requirements. Unlike REST APIs, you cannot use regular HTTP requests - you need an MCP-compatible client to handle the protocol properly."
  },
  {
    "objectID": "blog/07Sep2025-fastmcp-http-transport/index.html#basic-http-server-setup",
    "href": "blog/07Sep2025-fastmcp-http-transport/index.html#basic-http-server-setup",
    "title": "FastMCP HTTP Transport: Calling MCP Servers Over HTTP",
    "section": "Basic HTTP Server Setup",
    "text": "Basic HTTP Server Setup\nfrom fastmcp import FastMCP\n\nmcp = FastMCP(\"Demo Server\")\n\n@mcp.tool()\ndef get_weather(city: str) -&gt; str:\n    \"\"\"Get weather information for a city.\"\"\"\n    return f\"The weather in {city} is sunny and 72°F\"\n\nif __name__ == \"__main__\":\n    mcp.run(transport=\"http\", port=8000)"
  },
  {
    "objectID": "blog/07Sep2025-fastmcp-http-transport/index.html#call-the-mcp-server",
    "href": "blog/07Sep2025-fastmcp-http-transport/index.html#call-the-mcp-server",
    "title": "FastMCP HTTP Transport: Calling MCP Servers Over HTTP",
    "section": "Call the MCP Server",
    "text": "Call the MCP Server\nimport asyncio\nfrom fastmcp import Client\n\nclient = Client(\"http://localhost:8000/mcp\") # mcp is needed here\n\nasync def call_tool(city: str):\n    async with client:\n        result = await client.call_tool(\"get_weather\", {\"city\": city})\n        print(result)\n\nasyncio.run(call_tool(\"New York\"))\n\n\n\n\n\n\nNote\n\n\n\nWe need a FastMCP client or any LLM client that supports the MCP protocol to call the MCP server\nhttps://gofastmcp.com/getting-started/quickstart#call-your-server"
  },
  {
    "objectID": "blog/07Sep2025-fastmcp-http-transport/index.html#the-regular-post-request-wont-work",
    "href": "blog/07Sep2025-fastmcp-http-transport/index.html#the-regular-post-request-wont-work",
    "title": "FastMCP HTTP Transport: Calling MCP Servers Over HTTP",
    "section": "The regular POST request won’t work",
    "text": "The regular POST request won’t work\nimport requests\n\n# Call the tool via regular HTTP\nresponse = requests.post(\n    \"http://localhost:8000/mcp/\",\n    json={\"city\": \"New York\"}\n)\n\nthis will get something like `INFO:     127.0.0.1:59128 - \"POST /mcp/ HTTP/1.1\" 406 Not Acceptable`"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Jie Wang",
    "section": "",
    "text": "Data Engineer: May 2022 - present\nStatistical Programming: Apr 2016 - May 2022\nClinical Database Programmer: Jun 2012 - Apr 2016"
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Jie Wang",
    "section": "",
    "text": "Data Engineer: May 2022 - present\nStatistical Programming: Apr 2016 - May 2022\nClinical Database Programmer: Jun 2012 - Apr 2016"
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "Blog",
    "section": "",
    "text": "Order By\n      Default\n      \n        Date - Oldest\n      \n      \n        Date - Newest\n      \n      \n        Title\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\nTitle\n\n\n\nDate\n\n\n\nCategories\n\n\n\n\n\n\n\n\nFastMCP HTTP Transport: Calling MCP Servers Over HTTP\n\n\nSep 7, 2025\n\n\nmcp, http, fastmcp\n\n\n\n\n\n\nPrompt Engineering\n\n\nAug 30, 2025\n\n\nai, prompt-engineering, development, productivity\n\n\n\n\n\n\nMCP Client & Server Examples - Quick Reference\n\n\nJul 30, 2025\n\n\nmcp, python, AI\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/30Jul2025-mcp-client-server-basics/index.html",
    "href": "blog/30Jul2025-mcp-client-server-basics/index.html",
    "title": "MCP Client & Server Examples - Quick Reference",
    "section": "",
    "text": "Quick reference for basic MCP client and server implementation. Based on the official tutorial https://modelcontextprotocol.io/quickstart/client - keeping it here for easy access."
  },
  {
    "objectID": "blog/30Jul2025-mcp-client-server-basics/index.html#dependencies",
    "href": "blog/30Jul2025-mcp-client-server-basics/index.html#dependencies",
    "title": "MCP Client & Server Examples - Quick Reference",
    "section": "Dependencies",
    "text": "Dependencies\nRequired Python packages:\npip install fastmcp openai python-dotenv\nOr with uv:\nuv add fastmcp openai python-dotenv"
  },
  {
    "objectID": "blog/30Jul2025-mcp-client-server-basics/index.html#simple-mcp-server",
    "href": "blog/30Jul2025-mcp-client-server-basics/index.html#simple-mcp-server",
    "title": "MCP Client & Server Examples - Quick Reference",
    "section": "Simple MCP Server",
    "text": "Simple MCP Server\nBasic server using FastMCP with a tool, prompt, and resource:\n\n\n\n\n\n\nShow MCP Server Code\n\n\n\n\n\n\n\nsample_mcp_server.py\n\nfrom fastmcp import FastMCP\n\nmcp = FastMCP(\"Demo server\")\n\n@mcp.tool\ndef add(a: int, b: int) -&gt; int:\n    \"\"\"add 2 numbers\"\"\"\n    return a + b\n\n@mcp.prompt\ndef tell_a_joke() -&gt; str:\n    \"\"\"Tell me a programming joke\"\"\"\n    return \"Please tell me a funny programming joke that would make a developer laugh!\"\n\n@mcp.resource(\"data://config\")\ndef get_config() -&gt; dict[str, str | list[str]]:\n    \"\"\"Provides application configuration as JSON.\"\"\"\n    return {\n        \"theme\": \"dark\",\n        \"version\": \"1.2.0\",\n        \"features\": [\"tools\", \"resources\"],\n    }\n\nif __name__ == \"__main__\":\n    mcp.run()"
  },
  {
    "objectID": "blog/30Jul2025-mcp-client-server-basics/index.html#mcp-client-with-azure-openai",
    "href": "blog/30Jul2025-mcp-client-server-basics/index.html#mcp-client-with-azure-openai",
    "title": "MCP Client & Server Examples - Quick Reference",
    "section": "MCP Client with Azure OpenAI",
    "text": "MCP Client with Azure OpenAI\nClient that connects to the server and integrates with Azure OpenAI:\n\n\n\n\n\n\nShow MCP Client Code\n\n\n\n\n\n\n\nsample_mcp_client.py\n\nimport asyncio\nfrom contextlib import AsyncExitStack\nimport json\nimport os\n\nfrom mcp import ClientSession, StdioServerParameters\nfrom mcp.client.stdio import stdio_client\nfrom openai import AzureOpenAI\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\nclass MCPClient:\n    def __init__(self):\n        self.session: ClientSession | None = None\n        self.exit_stack = AsyncExitStack()\n        \n        self.azure_client = AzureOpenAI(\n            api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n            api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\", \"2024-10-21\"),\n            azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n        )\n        self.deployment_name = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\")\n\n    async def connect_to_server(self, server_script_path: str) -&gt; None:\n        \"\"\"Connect to an MCP server\"\"\"\n        is_python = server_script_path.endswith('.py')\n        command = \"python\" if is_python else \"node\"\n        \n        server_params = StdioServerParameters(\n            command=command,\n            args=[server_script_path],\n            env=None\n        )\n\n        stdio_transport = await self.exit_stack.enter_async_context(stdio_client(server_params))\n        self.stdio, self.write = stdio_transport\n        self.session = await self.exit_stack.enter_async_context(ClientSession(self.stdio, self.write))\n\n        await self.session.initialize()\n        \n        response = await self.session.list_tools()\n        tools = response.tools\n        print(\"Connected to server with tools:\", [tool.name for tool in tools])\n\n    async def process_query(self, query: str) -&gt; str:\n        \"\"\"Process a query using Azure OpenAI and available tools\"\"\"\n        messages = [{\"role\": \"user\", \"content\": query}]\n\n        response = await self.session.list_tools()\n        available_tools = [{\n            \"type\": \"function\",\n            \"function\": {\n                \"name\": tool.name,\n                \"description\": tool.description,\n                \"parameters\": tool.inputSchema\n            }\n        } for tool in response.tools]\n\n        response = self.azure_client.chat.completions.create(\n            model=self.deployment_name,\n            messages=messages,\n            tools=available_tools,\n            tool_choice=\"auto\"\n        )\n\n        final_text = []\n        assistant_message = response.choices[0].message\n\n        if assistant_message.content:\n            final_text.append(assistant_message.content)\n\n        messages.append({\n            \"role\": \"assistant\",\n            \"content\": assistant_message.content,\n            \"tool_calls\": assistant_message.tool_calls\n        })\n\n        if assistant_message.tool_calls:\n            for tool_call in assistant_message.tool_calls:\n                tool_name = tool_call.function.name\n                tool_args = json.loads(tool_call.function.arguments)\n\n                result = await self.session.call_tool(tool_name, tool_args)\n                final_text.append(f\"[Calling tool {tool_name} with args {tool_args}]\")\n\n                messages.append({\n                    \"role\": \"tool\",\n                    \"tool_call_id\": tool_call.id,\n                    \"content\": str(result.content)\n                })\n\n            response = self.azure_client.chat.completions.create(\n                model=self.deployment_name,\n                messages=messages,\n                tools=available_tools,\n                tool_choice=\"auto\"\n            )\n\n            if response.choices[0].message.content:\n                final_text.append(response.choices[0].message.content)\n\n        return \"\\n\".join(final_text)\n    \n    async def chat_loop(self) -&gt; None:\n        \"\"\"Run an interactive chat loop\"\"\"\n        print(\"MCP Client Started! Type 'quit' to exit.\")\n\n        while True:\n            try:\n                query = input(\"\\nQuery: \").strip()\n                if query.lower() == 'quit':\n                    break\n\n                response = await self.process_query(query)\n                print(f\"\\n{response}\")\n\n            except Exception as e:\n                print(f\"Error: {str(e)}\")\n\n    async def cleanup(self) -&gt; None:\n        \"\"\"Clean up resources\"\"\"\n        await self.exit_stack.aclose()\n\nasync def main() -&gt; None:\n    if len(sys.argv) &lt; 2:\n        print(\"Usage: python client.py &lt;path_to_server_script&gt;\")\n        sys.exit(1)\n\n    client = MCPClient()\n    try:\n        await client.connect_to_server(sys.argv[1])\n        await client.chat_loop()\n    finally:\n        await client.cleanup()\n\nif __name__ == \"__main__\":\n    import sys\n    asyncio.run(main())"
  },
  {
    "objectID": "blog/30Jul2025-mcp-client-server-basics/index.html#usage",
    "href": "blog/30Jul2025-mcp-client-server-basics/index.html#usage",
    "title": "MCP Client & Server Examples - Quick Reference",
    "section": "Usage",
    "text": "Usage\nRun the client with your server:\nuv run sample_mcp_client.py sample_mcp_server.py"
  },
  {
    "objectID": "blog/30Jul2025-mcp-client-server-basics/index.html#how-it-works",
    "href": "blog/30Jul2025-mcp-client-server-basics/index.html#how-it-works",
    "title": "MCP Client & Server Examples - Quick Reference",
    "section": "How It Works",
    "text": "How It Works\nServer provides:\n\nTools - Functions AI can call (add)\nPrompts - Message templates (tell_a_joke)\n\nResources - Static data (config)\n\nClient handles:\n\nServer connection via stdio\nTool discovery and formatting\nConversation flow between user, Azure OpenAI, and tools"
  },
  {
    "objectID": "blog/30Jul2025-mcp-client-server-basics/index.html#development",
    "href": "blog/30Jul2025-mcp-client-server-basics/index.html#development",
    "title": "MCP Client & Server Examples - Quick Reference",
    "section": "Development",
    "text": "Development\nInspect your server with FastMCP’s dev mode:\nfastmcp dev sample_mcp_server.py\nThis gives you a web interface to test tools and explore server capabilities."
  }
]