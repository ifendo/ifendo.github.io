[
  {
    "objectID": "tools.html",
    "href": "tools.html",
    "title": "Tools",
    "section": "",
    "text": "R Related\n\n\nPython Related\n\n\nAI Related"
  },
  {
    "objectID": "blog/30Aug2025-prompt-engineering-tips/index.html",
    "href": "blog/30Aug2025-prompt-engineering-tips/index.html",
    "title": "Prompt Engineering",
    "section": "",
    "text": "Prompt engineering has become an essential skill for developers working with AI models. Whether you’re using ChatGPT, Claude, or other language models, the quality of your prompts directly impacts the usefulness of the responses you get."
  },
  {
    "objectID": "blog/30Aug2025-prompt-engineering-tips/index.html#core-principles",
    "href": "blog/30Aug2025-prompt-engineering-tips/index.html#core-principles",
    "title": "Prompt Engineering",
    "section": "Core Principles",
    "text": "Core Principles\nThe foundation of good prompt engineering rests on these key principles:\n\nUse role-playing - “Act as a senior data engineer mentoring a junior. Explain why data quality matters in ETL processes”\nBe specific and clear - Instead of “Write about AI”, try “Write a 300-word explanation of transformers for developers”\nProvide context and examples - Include role, audience, and format requirements\nUse structured formats - JSON, bullet points, step-by-step instructions\nIterate and refine - Start simple, add complexity gradually"
  },
  {
    "objectID": "blog/30Aug2025-prompt-engineering-tips/index.html#role-context-setting",
    "href": "blog/30Aug2025-prompt-engineering-tips/index.html#role-context-setting",
    "title": "Prompt Engineering",
    "section": "Role & Context Setting",
    "text": "Role & Context Setting\nSetting the right context dramatically improves response quality. Here’s how to do it effectively:\nSet the scene:\nYou are a senior Python developer reviewing FastAPI code.\nFocus on performance and security issues.\nYour audience is junior developers.\nProvide examples (Few-shot prompting):\nClassify sentiment:\n\"I love this!\" → Positive\n\"This is terrible\" → Negative\n\"It's okay\" → Neutral\n\nNow classify: \"Amazing quality!\"\nThis approach gives the AI model concrete examples of what you expect, leading to more consistent results."
  },
  {
    "objectID": "blog/30Aug2025-prompt-engineering-tips/index.html#advanced-techniques",
    "href": "blog/30Aug2025-prompt-engineering-tips/index.html#advanced-techniques",
    "title": "Prompt Engineering",
    "section": "Advanced Techniques",
    "text": "Advanced Techniques\n\nChain of Thought\nBreak down complex problems into steps:\nCalculate 15% tip on $47.50\n\nThink step by step:\n1. Convert percentage to decimal: 15% = 0.15\n2. Multiply: $47.50 × 0.15 = $7.125\n3. Round to nearest cent: $7.13\n\n\nOutput Formatting\nSpecify exactly how you want the response structured:\nRespond in JSON:\n{\"summary\": \"...\", \"confidence\": 0.85}\n\n\nConstraints\nSet clear boundaries:\n\nLength: “In exactly 100 words”\nStyle: “Use bullet points only”\n\nScope: “Python solutions only”"
  },
  {
    "objectID": "blog/30Aug2025-prompt-engineering-tips/index.html#common-pitfalls-best-practices",
    "href": "blog/30Aug2025-prompt-engineering-tips/index.html#common-pitfalls-best-practices",
    "title": "Prompt Engineering",
    "section": "Common Pitfalls & Best Practices",
    "text": "Common Pitfalls & Best Practices\n\n\n\n\n\n\nWarningAvoid These Mistakes\n\n\n\n\nVague instructions that leave too much room for interpretation\nMissing context about your specific use case\nOverloading a single prompt with too many requirements\n\n\n\n\n\n\n\n\n\nTipBest Practices\n\n\n\n\nTest your prompts with edge cases\nDocument successful prompt patterns for reuse\nVersion control your prompts like code\nUse system prompts for consistency across conversations\nControl temperature settings (creativity vs precision)"
  },
  {
    "objectID": "blog/30Aug2025-prompt-engineering-tips/index.html#practical-examples",
    "href": "blog/30Aug2025-prompt-engineering-tips/index.html#practical-examples",
    "title": "Prompt Engineering",
    "section": "Practical Examples",
    "text": "Practical Examples\n\nCode Generation Prompt\nHere’s a comprehensive prompt template for generating production-ready code:\n&lt;role&gt;\nYou are a senior Python expert developer with expertise in clean, \nproduction-ready code. Your audience is experienced developers who \nvalue efficiency and maintainability.\n&lt;/role&gt;\n\n&lt;task&gt;\nGenerate Python code following these exact specifications:\n&lt;/task&gt;\n\n&lt;code_requirements&gt;\n- Python 3.10+ syntax with complete type annotations\n- PEP8 compliant (must pass `ruff check .`)\n- Prefer standard library; avoid unnecessary dependencies\n- Use only stable, popular packages when needed\n- Use `polars` instead of `pandas` for data operations\n- Include docstrings with examples\n- Minimal implementation - no over-engineering\n&lt;/code_requirements&gt;\n\n&lt;output_format&gt;\nComplete, runnable code with:\n1. Necessary imports at top\n2. Type-annotated functions with docstrings\n3. Main execution (if applicable)\n4. Small usage example\n5. Pytest unit test (if relevant)\n&lt;/output_format&gt;\n\n\nCode Review Prompt\nFor reviewing existing code:\n&lt;role&gt;\nYou are a senior Python code reviewer with expertise in \nproduction-ready code quality.\n&lt;/role&gt;\n\n&lt;review_requirements&gt;\n- Check Python 3.10+ syntax and type annotations\n- Verify PEP8 compliance\n- Evaluate package choices\n- Identify over-engineering or unnecessary complexity\n- Review comment quality\n&lt;/review_requirements&gt;\n\n&lt;output_format&gt;\n## Issues Found\n- **Critical**: [Security, functionality issues]\n- **Improvements**: [Code quality suggestions]\n- **Style**: [PEP8, formatting issues]\n\n## Recommendations\n[Specific, actionable suggestions with examples]\n&lt;/output_format&gt;"
  },
  {
    "objectID": "blog/30Aug2025-prompt-engineering-tips/index.html#key-takeaways",
    "href": "blog/30Aug2025-prompt-engineering-tips/index.html#key-takeaways",
    "title": "Prompt Engineering",
    "section": "Key Takeaways",
    "text": "Key Takeaways\nEffective prompt engineering is about clear communication with AI models. The time you invest in crafting good prompts pays dividends in the quality and usefulness of the responses you receive.\nStart with these fundamentals: 1. Be specific about what you want 2. Provide context and examples 3. Structure your requests clearly 4. Iterate and improve your prompts over time\nAs AI models continue to evolve, these prompt engineering skills will become increasingly valuable for developers who want to leverage AI effectively in their workflows."
  },
  {
    "objectID": "blog/30Aug2025-prompt-engineering-tips/index.html#references",
    "href": "blog/30Aug2025-prompt-engineering-tips/index.html#references",
    "title": "Prompt Engineering",
    "section": "References",
    "text": "References\n\nOpenAI Prompting Guide\nAnthropic Prompt Engineering\nPrompt Engineering Guide"
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "Blog",
    "section": "",
    "text": "Order By\n      Default\n      \n        Date - Oldest\n      \n      \n        Date - Newest\n      \n      \n        Title\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\nTitle\n\n\n\nDate\n\n\n\nCategories\n\n\n\n\n\n\n\n\nUV: The Fast Python Package Manager\n\n\nSep 14, 2025\n\n\npython, tools, uv\n\n\n\n\n\n\nFastMCP HTTP Transport: Calling MCP Servers Over HTTP\n\n\nSep 7, 2025\n\n\nmcp, http, fastmcp\n\n\n\n\n\n\nPrompt Engineering\n\n\nAug 30, 2025\n\n\nai, prompt-engineering, development, productivity\n\n\n\n\n\n\nMCP Client & Server Examples - Quick Reference\n\n\nJul 30, 2025\n\n\nmcp, python, AI\n\n\n\n\n\n\nMy Notes on the LLM CLI Tool\n\n\nSep 21, 2024\n\n\nai, cli, tools, tutorial\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/07Sep2025-fastmcp-http-transport/index.html",
    "href": "blog/07Sep2025-fastmcp-http-transport/index.html",
    "title": "FastMCP HTTP Transport: Calling MCP Servers Over HTTP",
    "section": "",
    "text": "FastMCP provides an HTTP transport layer for Model Context Protocol (MCP) servers, but requires a proper MCP client to communicate. This post demonstrates the correct way to call an MCP server over HTTP using FastMCP."
  },
  {
    "objectID": "blog/07Sep2025-fastmcp-http-transport/index.html#what-is-fastmcp-http-transport",
    "href": "blog/07Sep2025-fastmcp-http-transport/index.html#what-is-fastmcp-http-transport",
    "title": "FastMCP HTTP Transport: Calling MCP Servers Over HTTP",
    "section": "What is FastMCP HTTP Transport?",
    "text": "What is FastMCP HTTP Transport?\nFastMCP’s HTTP transport exposes MCP servers over HTTP, but maintains the MCP protocol requirements. Unlike REST APIs, you cannot use regular HTTP requests - you need an MCP-compatible client to handle the protocol properly."
  },
  {
    "objectID": "blog/07Sep2025-fastmcp-http-transport/index.html#basic-http-server-setup",
    "href": "blog/07Sep2025-fastmcp-http-transport/index.html#basic-http-server-setup",
    "title": "FastMCP HTTP Transport: Calling MCP Servers Over HTTP",
    "section": "Basic HTTP Server Setup",
    "text": "Basic HTTP Server Setup\nfrom fastmcp import FastMCP\n\nmcp = FastMCP(\"Demo Server\")\n\n@mcp.tool()\ndef get_weather(city: str) -&gt; str:\n    \"\"\"Get weather information for a city.\"\"\"\n    return f\"The weather in {city} is sunny and 72°F\"\n\nif __name__ == \"__main__\":\n    mcp.run(transport=\"http\", port=8000)"
  },
  {
    "objectID": "blog/07Sep2025-fastmcp-http-transport/index.html#call-the-mcp-server",
    "href": "blog/07Sep2025-fastmcp-http-transport/index.html#call-the-mcp-server",
    "title": "FastMCP HTTP Transport: Calling MCP Servers Over HTTP",
    "section": "Call the MCP Server",
    "text": "Call the MCP Server\nimport asyncio\nfrom fastmcp import Client\n\nclient = Client(\"http://localhost:8000/mcp\") # mcp is needed here\n\nasync def call_tool(city: str):\n    async with client:\n        result = await client.call_tool(\"get_weather\", {\"city\": city})\n        print(result)\n\nasyncio.run(call_tool(\"New York\"))\n\n\n\n\n\n\nNote\n\n\n\nWe need a FastMCP client or any LLM client that supports the MCP protocol to call the MCP server\nhttps://gofastmcp.com/getting-started/quickstart#call-your-server"
  },
  {
    "objectID": "blog/07Sep2025-fastmcp-http-transport/index.html#the-regular-post-request-wont-work",
    "href": "blog/07Sep2025-fastmcp-http-transport/index.html#the-regular-post-request-wont-work",
    "title": "FastMCP HTTP Transport: Calling MCP Servers Over HTTP",
    "section": "The regular POST request won’t work",
    "text": "The regular POST request won’t work\nimport requests\n\n# Call the tool via regular HTTP\nresponse = requests.post(\n    \"http://localhost:8000/mcp/\",\n    json={\"city\": \"New York\"}\n)\n\nthis will get something like `INFO:     127.0.0.1:59128 - \"POST /mcp/ HTTP/1.1\" 406 Not Acceptable`"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Jie Wang",
    "section": "",
    "text": "Data Engineer: May 2022 - present\nStatistical Programming: Apr 2016 - May 2022\nClinical Database Programmer: Jun 2012 - Apr 2016"
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Jie Wang",
    "section": "",
    "text": "Data Engineer: May 2022 - present\nStatistical Programming: Apr 2016 - May 2022\nClinical Database Programmer: Jun 2012 - Apr 2016"
  },
  {
    "objectID": "blog/21Sep2024-llm-cli-notes/index.html",
    "href": "blog/21Sep2024-llm-cli-notes/index.html",
    "title": "My Notes on the LLM CLI Tool",
    "section": "",
    "text": "The LLM CLI tool by Simon Willison provides a simple yet powerful way to interact with various language models directly from your command line. This guide covers installation, configuration, and practical usage patterns to help you get started with this versatile tool."
  },
  {
    "objectID": "blog/21Sep2024-llm-cli-notes/index.html#links",
    "href": "blog/21Sep2024-llm-cli-notes/index.html#links",
    "title": "My Notes on the LLM CLI Tool",
    "section": "Links",
    "text": "Links\n\nGitHub: https://github.com/simonw/llm\nDocumentation: https://llm.datasette.io/en/stable/"
  },
  {
    "objectID": "blog/21Sep2024-llm-cli-notes/index.html#installation",
    "href": "blog/21Sep2024-llm-cli-notes/index.html#installation",
    "title": "My Notes on the LLM CLI Tool",
    "section": "Installation",
    "text": "Installation\nUsing uv:\nuv tool install llm"
  },
  {
    "objectID": "blog/21Sep2024-llm-cli-notes/index.html#plugin-installation",
    "href": "blog/21Sep2024-llm-cli-notes/index.html#plugin-installation",
    "title": "My Notes on the LLM CLI Tool",
    "section": "Plugin Installation",
    "text": "Plugin Installation\nInstall plugins for specific providers (using Azure as example):\nllm install llm-azure\n\nllm-azure: https://github.com/fabge/llm-azure"
  },
  {
    "objectID": "blog/21Sep2024-llm-cli-notes/index.html#api-key-configuration",
    "href": "blog/21Sep2024-llm-cli-notes/index.html#api-key-configuration",
    "title": "My Notes on the LLM CLI Tool",
    "section": "API Key Configuration",
    "text": "API Key Configuration\nSet your API key:\nllm keys set azure"
  },
  {
    "objectID": "blog/21Sep2024-llm-cli-notes/index.html#azure-setup",
    "href": "blog/21Sep2024-llm-cli-notes/index.html#azure-setup",
    "title": "My Notes on the LLM CLI Tool",
    "section": "Azure Setup",
    "text": "Azure Setup\nAdd a configuration file to the required azure directory of llm installation:\ndirname $(llm logs path)\nThe configuration file should look like:\n- model_id: gpt-4-32k\n  model_name: gpt-4-32k\n  api_base: https://your_deployment.openai.azure.com/\n  api_version: '2023-05-15'\n\n- model_id: text-embedding-3-small\n  embedding_model: true\n  model_name: text-embedding-3-small\n  api_base: https://your_deployment.openai.azure.com/\n  api_version: '2023-05-14'\n\nmodel_id: Used by the LLM CLI\nmodel_name: Passed to the Azure API"
  },
  {
    "objectID": "blog/21Sep2024-llm-cli-notes/index.html#set-default-model",
    "href": "blog/21Sep2024-llm-cli-notes/index.html#set-default-model",
    "title": "My Notes on the LLM CLI Tool",
    "section": "Set Default Model",
    "text": "Set Default Model\nllm models default &lt;model_id&gt;"
  },
  {
    "objectID": "blog/21Sep2024-llm-cli-notes/index.html#using-llm-prompts",
    "href": "blog/21Sep2024-llm-cli-notes/index.html#using-llm-prompts",
    "title": "My Notes on the LLM CLI Tool",
    "section": "Using LLM Prompts",
    "text": "Using LLM Prompts\n\nPipe Input\ncat my_python_script.py | llm \"explain this code\"\n\n\nAttachments\nllm \"describe this image\" -a https://static.simonwillison.net/static/2024/pelicans.jpg\nSupports both URLs and file paths.\n\n\nSystem Prompts\necho \"import fastapi\" | llm \"explain this code\" -s \"You are a python expert and explain complex concepts concisely with simple examples\""
  },
  {
    "objectID": "blog/21Sep2024-llm-cli-notes/index.html#templates",
    "href": "blog/21Sep2024-llm-cli-notes/index.html#templates",
    "title": "My Notes on the LLM CLI Tool",
    "section": "Templates",
    "text": "Templates\n\nList Templates\nllm templates\n\n\nEdit Templates\nllm templates edit summarize\nProvide default values for parameters:\nprompt: 'Translate to $language: $input'\ndefaults:\n  language: 中文\n\n\nUse Templates\nllm -t translate -p language '中文' \"I love you\""
  },
  {
    "objectID": "blog/14Sep2025-uv-python-manager/index.html",
    "href": "blog/14Sep2025-uv-python-manager/index.html",
    "title": "UV: The Fast Python Package Manager",
    "section": "",
    "text": "UV is a drop-in replacement for pip and pip-tools that’s designed to be significantly faster and more reliable. Created by Astral (the team behind Ruff), it aims to solve common Python packaging problems while maintaining compatibility with existing workflows.\nKey benefits: - 10-100x faster than pip for most operations\n- Better dependency resolution with clear error messages\n- Cross-platform support (Windows, macOS, Linux)\n- Drop-in replacement for pip commands"
  },
  {
    "objectID": "blog/14Sep2025-uv-python-manager/index.html#what-is-uv",
    "href": "blog/14Sep2025-uv-python-manager/index.html#what-is-uv",
    "title": "UV: The Fast Python Package Manager",
    "section": "",
    "text": "UV is a drop-in replacement for pip and pip-tools that’s designed to be significantly faster and more reliable. Created by Astral (the team behind Ruff), it aims to solve common Python packaging problems while maintaining compatibility with existing workflows.\nKey benefits: - 10-100x faster than pip for most operations\n- Better dependency resolution with clear error messages\n- Cross-platform support (Windows, macOS, Linux)\n- Drop-in replacement for pip commands"
  },
  {
    "objectID": "blog/14Sep2025-uv-python-manager/index.html#installation",
    "href": "blog/14Sep2025-uv-python-manager/index.html#installation",
    "title": "UV: The Fast Python Package Manager",
    "section": "Installation",
    "text": "Installation\nInstall uv using the official installer:\n# macOS\ncurl -LsSf https://astral.sh/uv/install.sh | sh"
  },
  {
    "objectID": "blog/14Sep2025-uv-python-manager/index.html#upgrading-uv",
    "href": "blog/14Sep2025-uv-python-manager/index.html#upgrading-uv",
    "title": "UV: The Fast Python Package Manager",
    "section": "Upgrading uv",
    "text": "Upgrading uv\nuv self update"
  },
  {
    "objectID": "blog/14Sep2025-uv-python-manager/index.html#features",
    "href": "blog/14Sep2025-uv-python-manager/index.html#features",
    "title": "UV: The Fast Python Package Manager",
    "section": "Features",
    "text": "Features\n\nPython versions\nuv python install\nuv python list\nuv python find\nuv python pin\nuv python uninstall\n\n\nScripts\nuv run\nuv add --script\nuv remove --script\n\n\nProjects\nuv init\nuv add\nuv remove\nuv sync\nuv lock\nuv run\nuv tree\nuv build\nuv publish\n\nProjects details\n\n\n\n\n\n\n\n\nDimension\nuv init --package mypackage\nuv init --lib mypackage\n\n\n\n\nPurpose / template\nCreates a packaged application (good for CLIs or installable apps).\nCreates a library intended to be imported and published.\n\n\nPackaging behavior\nAdds packaging metadata so the project is installable.\n--lib implies --package; libraries are always installable.\n\n\nLayout\nUses a src/ layout with a top‑level module directory and __init__.py.\nAlso uses a src/ layout with a top‑level module directory and __init__.py.\n\n\nType markers\nNo py.typed by default.\nIncludes py.typed so downstream users get inline type hints.\n\n\nBuild system\nAdds a [build-system] section (default uv_build), enabling builds/installs.\nAlso adds a [build-system] section (default uv_build).\n\n\nEntrypoint / scripts\nIncludes a console script entry in pyproject.toml (e.g., [project.scripts] mypackage = \"mypackage:main\").\nNo console script by default; focuses on importable APIs.\n\n\nHow you run it\nRun the generated command via uv run mypackage (mapped to mypackage:main).\nImport and call the API (e.g., import mypackage) or run Python directly.\n\n\nIntended use cases\nCommand‑line tools, apps you install and execute, projects that benefit from an entrypoint.\nReusable packages for other projects, publishable libraries with type hints.\n\n\nCLI/flag nuances\nExplicitly selects the “packaged application” template.\nSelecting --lib automatically selects packaging; same src/ layout but adds py.typed.\n\n\n\n\n\n\nTools\nuv tool install\nuv tool uninstall\nuv tool list"
  },
  {
    "objectID": "blog/14Sep2025-uv-python-manager/index.html#references",
    "href": "blog/14Sep2025-uv-python-manager/index.html#references",
    "title": "UV: The Fast Python Package Manager",
    "section": "References",
    "text": "References\n\nUV Documentation"
  },
  {
    "objectID": "blog/30Jul2025-mcp-client-server-basics/index.html",
    "href": "blog/30Jul2025-mcp-client-server-basics/index.html",
    "title": "MCP Client & Server Examples - Quick Reference",
    "section": "",
    "text": "Quick reference for basic MCP client and server implementation. Based on the official tutorial https://modelcontextprotocol.io/quickstart/client - keeping it here for easy access."
  },
  {
    "objectID": "blog/30Jul2025-mcp-client-server-basics/index.html#dependencies",
    "href": "blog/30Jul2025-mcp-client-server-basics/index.html#dependencies",
    "title": "MCP Client & Server Examples - Quick Reference",
    "section": "Dependencies",
    "text": "Dependencies\nRequired Python packages:\npip install fastmcp openai python-dotenv\nOr with uv:\nuv add fastmcp openai python-dotenv"
  },
  {
    "objectID": "blog/30Jul2025-mcp-client-server-basics/index.html#simple-mcp-server",
    "href": "blog/30Jul2025-mcp-client-server-basics/index.html#simple-mcp-server",
    "title": "MCP Client & Server Examples - Quick Reference",
    "section": "Simple MCP Server",
    "text": "Simple MCP Server\nBasic server using FastMCP with a tool, prompt, and resource:\n\n\n\n\n\n\nNoteShow MCP Server Code\n\n\n\n\n\n\n\nsample_mcp_server.py\n\nfrom fastmcp import FastMCP\n\nmcp = FastMCP(\"Demo server\")\n\n@mcp.tool\ndef add(a: int, b: int) -&gt; int:\n    \"\"\"add 2 numbers\"\"\"\n    return a + b\n\n@mcp.prompt\ndef tell_a_joke() -&gt; str:\n    \"\"\"Tell me a programming joke\"\"\"\n    return \"Please tell me a funny programming joke that would make a developer laugh!\"\n\n@mcp.resource(\"data://config\")\ndef get_config() -&gt; dict[str, str | list[str]]:\n    \"\"\"Provides application configuration as JSON.\"\"\"\n    return {\n        \"theme\": \"dark\",\n        \"version\": \"1.2.0\",\n        \"features\": [\"tools\", \"resources\"],\n    }\n\nif __name__ == \"__main__\":\n    mcp.run()"
  },
  {
    "objectID": "blog/30Jul2025-mcp-client-server-basics/index.html#mcp-client-with-azure-openai",
    "href": "blog/30Jul2025-mcp-client-server-basics/index.html#mcp-client-with-azure-openai",
    "title": "MCP Client & Server Examples - Quick Reference",
    "section": "MCP Client with Azure OpenAI",
    "text": "MCP Client with Azure OpenAI\nClient that connects to the server and integrates with Azure OpenAI:\n\n\n\n\n\n\nNoteShow MCP Client Code\n\n\n\n\n\n\n\nsample_mcp_client.py\n\nimport asyncio\nfrom contextlib import AsyncExitStack\nimport json\nimport os\n\nfrom mcp import ClientSession, StdioServerParameters\nfrom mcp.client.stdio import stdio_client\nfrom openai import AzureOpenAI\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\nclass MCPClient:\n    def __init__(self):\n        self.session: ClientSession | None = None\n        self.exit_stack = AsyncExitStack()\n        \n        self.azure_client = AzureOpenAI(\n            api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n            api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\", \"2024-10-21\"),\n            azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n        )\n        self.deployment_name = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\")\n\n    async def connect_to_server(self, server_script_path: str) -&gt; None:\n        \"\"\"Connect to an MCP server\"\"\"\n        is_python = server_script_path.endswith('.py')\n        command = \"python\" if is_python else \"node\"\n        \n        server_params = StdioServerParameters(\n            command=command,\n            args=[server_script_path],\n            env=None\n        )\n\n        stdio_transport = await self.exit_stack.enter_async_context(stdio_client(server_params))\n        self.stdio, self.write = stdio_transport\n        self.session = await self.exit_stack.enter_async_context(ClientSession(self.stdio, self.write))\n\n        await self.session.initialize()\n        \n        response = await self.session.list_tools()\n        tools = response.tools\n        print(\"Connected to server with tools:\", [tool.name for tool in tools])\n\n    async def process_query(self, query: str) -&gt; str:\n        \"\"\"Process a query using Azure OpenAI and available tools\"\"\"\n        messages = [{\"role\": \"user\", \"content\": query}]\n\n        response = await self.session.list_tools()\n        available_tools = [{\n            \"type\": \"function\",\n            \"function\": {\n                \"name\": tool.name,\n                \"description\": tool.description,\n                \"parameters\": tool.inputSchema\n            }\n        } for tool in response.tools]\n\n        response = self.azure_client.chat.completions.create(\n            model=self.deployment_name,\n            messages=messages,\n            tools=available_tools,\n            tool_choice=\"auto\"\n        )\n\n        final_text = []\n        assistant_message = response.choices[0].message\n\n        if assistant_message.content:\n            final_text.append(assistant_message.content)\n\n        messages.append({\n            \"role\": \"assistant\",\n            \"content\": assistant_message.content,\n            \"tool_calls\": assistant_message.tool_calls\n        })\n\n        if assistant_message.tool_calls:\n            for tool_call in assistant_message.tool_calls:\n                tool_name = tool_call.function.name\n                tool_args = json.loads(tool_call.function.arguments)\n\n                result = await self.session.call_tool(tool_name, tool_args)\n                final_text.append(f\"[Calling tool {tool_name} with args {tool_args}]\")\n\n                messages.append({\n                    \"role\": \"tool\",\n                    \"tool_call_id\": tool_call.id,\n                    \"content\": str(result.content)\n                })\n\n            response = self.azure_client.chat.completions.create(\n                model=self.deployment_name,\n                messages=messages,\n                tools=available_tools,\n                tool_choice=\"auto\"\n            )\n\n            if response.choices[0].message.content:\n                final_text.append(response.choices[0].message.content)\n\n        return \"\\n\".join(final_text)\n    \n    async def chat_loop(self) -&gt; None:\n        \"\"\"Run an interactive chat loop\"\"\"\n        print(\"MCP Client Started! Type 'quit' to exit.\")\n\n        while True:\n            try:\n                query = input(\"\\nQuery: \").strip()\n                if query.lower() == 'quit':\n                    break\n\n                response = await self.process_query(query)\n                print(f\"\\n{response}\")\n\n            except Exception as e:\n                print(f\"Error: {str(e)}\")\n\n    async def cleanup(self) -&gt; None:\n        \"\"\"Clean up resources\"\"\"\n        await self.exit_stack.aclose()\n\nasync def main() -&gt; None:\n    if len(sys.argv) &lt; 2:\n        print(\"Usage: python client.py &lt;path_to_server_script&gt;\")\n        sys.exit(1)\n\n    client = MCPClient()\n    try:\n        await client.connect_to_server(sys.argv[1])\n        await client.chat_loop()\n    finally:\n        await client.cleanup()\n\nif __name__ == \"__main__\":\n    import sys\n    asyncio.run(main())"
  },
  {
    "objectID": "blog/30Jul2025-mcp-client-server-basics/index.html#usage",
    "href": "blog/30Jul2025-mcp-client-server-basics/index.html#usage",
    "title": "MCP Client & Server Examples - Quick Reference",
    "section": "Usage",
    "text": "Usage\nRun the client with your server:\nuv run sample_mcp_client.py sample_mcp_server.py"
  },
  {
    "objectID": "blog/30Jul2025-mcp-client-server-basics/index.html#how-it-works",
    "href": "blog/30Jul2025-mcp-client-server-basics/index.html#how-it-works",
    "title": "MCP Client & Server Examples - Quick Reference",
    "section": "How It Works",
    "text": "How It Works\nServer provides:\n\nTools - Functions AI can call (add)\nPrompts - Message templates (tell_a_joke)\n\nResources - Static data (config)\n\nClient handles:\n\nServer connection via stdio\nTool discovery and formatting\nConversation flow between user, Azure OpenAI, and tools"
  },
  {
    "objectID": "blog/30Jul2025-mcp-client-server-basics/index.html#development",
    "href": "blog/30Jul2025-mcp-client-server-basics/index.html#development",
    "title": "MCP Client & Server Examples - Quick Reference",
    "section": "Development",
    "text": "Development\nInspect your server with FastMCP’s dev mode:\nfastmcp dev sample_mcp_server.py\nThis gives you a web interface to test tools and explore server capabilities."
  }
]